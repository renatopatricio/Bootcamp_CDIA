ğŸ“Š Resultados PÃ³s-Tuning
ğŸ”¹ Random Forest (Tuned)
Classe 1 (falha)
Precision: 0.46
Recall: 0.53
F1: 0.49
AcurÃ¡cia geral: 97.9%
ğŸ‘‰ Bom equilÃ­brio: melhorou recall em relaÃ§Ã£o ao baseline e manteve acurÃ¡cia alta.

ğŸ”¹ XGBoost (Tuned)
Classe 1 (falha)
Precision: 0.35
Recall: 0.55
F1: 0.43
AcurÃ¡cia geral: 97.2%
ğŸ‘‰ Ganhou recall, sacrificando precisÃ£o. Ãštil em cenÃ¡rios onde nÃ£o perder falhas Ã© prioridade.

ğŸ”¹ Stacking Ensemble (RF + XGBoost)
Classe 1 (falha)
Precision: 0.15
Recall: 0.80
F1: 0.25
AcurÃ¡cia geral: 91.3%
ğŸ‘‰ Recall explodiu para 80%, mas a precisÃ£o caiu muito (muitos falsos positivos). Isso pode ser valioso em casos crÃ­ticos de manutenÃ§Ã£o preditiva, onde o custo de uma falha nÃ£o detectada Ã© enorme.

âœ… ConclusÃµes Passo 6
Random Forest Tunado: melhor opÃ§Ã£o se a empresa valoriza equilÃ­brio entre acerto geral e custo dos falsos positivos.
XGBoost Tunado: ligeiramente melhor em recall, mas menos preciso.
Stacking Ensemble: se a prioridade mÃ¡xima for detectar falhas (mesmo com muitos alarmes falsos), Ã© a melhor escolha.

Na prÃ¡tica real:

Para manutenÃ§Ã£o preditiva em fÃ¡bricas, geralmente escolhe-se recall alto (nÃ£o deixar falhas passarem batidas).
Uma estratÃ©gia prÃ¡tica Ã© implementar o Ensemble para monitoramento crÃ­tico e, em paralelo, usar o RF Tunado para anÃ¡lises confirmatÃ³rias e relatÃ³rios.
