{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38984dea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "üìä Resultados P√≥s-Tuning\n",
    "üîπ Random Forest (Tuned)\n",
    "Classe 1 (falha)\n",
    "Precision: 0.46\n",
    "Recall: 0.53\n",
    "F1: 0.49\n",
    "Acur√°cia geral: 97.9%\n",
    "üëâ Bom equil√≠brio: melhorou recall em rela√ß√£o ao baseline e manteve acur√°cia alta.\n",
    "\n",
    "üîπ XGBoost (Tuned)\n",
    "Classe 1 (falha)\n",
    "Precision: 0.35\n",
    "Recall: 0.55\n",
    "F1: 0.43\n",
    "Acur√°cia geral: 97.2%\n",
    "üëâ Ganhou recall, sacrificando precis√£o. √ötil em cen√°rios onde n√£o perder falhas √© prioridade.\n",
    "\n",
    "üîπ Stacking Ensemble (RF + XGBoost)\n",
    "Classe 1 (falha)\n",
    "Precision: 0.15\n",
    "Recall: 0.80\n",
    "F1: 0.25\n",
    "Acur√°cia geral: 91.3%\n",
    "üëâ Recall explodiu para 80%, mas a precis√£o caiu muito (muitos falsos positivos). Isso pode ser valioso em casos cr√≠ticos de manuten√ß√£o preditiva, onde o custo de uma falha n√£o detectada √© enorme.\n",
    "\n",
    "‚úÖ Conclus√µes Passo 6\n",
    "Random Forest Tunado: melhor op√ß√£o se a empresa valoriza equil√≠brio entre acerto geral e custo dos falsos positivos.\n",
    "XGBoost Tunado: ligeiramente melhor em recall, mas menos preciso.\n",
    "Stacking Ensemble: se a prioridade m√°xima for detectar falhas (mesmo com muitos alarmes falsos), √© a melhor escolha.\n",
    "\n",
    "Na pr√°tica real:\n",
    "\n",
    "Para manuten√ß√£o preditiva em f√°bricas, geralmente escolhe-se recall alto (n√£o deixar falhas passarem batidas).\n",
    "Uma estrat√©gia pr√°tica √© implementar o Ensemble para monitoramento cr√≠tico e, em paralelo, usar o RF Tunado para an√°lises confirmat√≥rias e relat√≥rios."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
